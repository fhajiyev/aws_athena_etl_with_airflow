# CREATE TABLE `data_source_attribute` (
#   `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
#   `created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,
#   `updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
#   `data_source_id` varchar(255) NOT NULL,
#   `organization_id` bigint(20) unsigned NOT NULL,
#   `name` varchar(255) NOT NULL,
#   `description` text NOT NULL,
#   `data_type` varchar(255) NOT NULL,
#   `attribute_type` varchar(255) NOT NULL,
#   PRIMARY KEY (`id`)
# ) ENGINE=InnoDB AUTO_INCREMENT=360 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
---
pipeline_key: segmentsvc_ls_data_source_attribute
pipeline_type: mysql_unload_s3
pipeline_dag_configs:
  start_date: 2020-11-24 09:00:00
  schedule_interval: "0 * * * *"
mysql:
  conn_id: segmentsvc_mysql
  table_name: data_source_attribute
  increment_key: id
  increment_key_type: dump
  fields:
    - id
    - created_at
    - updated_at
    - data_source_id
    - organization_id
    - name
    - description
    - data_type
    - attribute_type
s3:
  bucket: "{{ var.value.get('server_env', 'prod') }}-buzzvil-data-lake"
  prefix: segmentsvc/landing_snapshot/data_source_attribute/year={year}/month={month}/day={day}/hour={hour}
  file_key: segmentsvc_ls_data_source_attribute
  data_format: parquet
athena:
  create_table_syntax: |
    CREATE EXTERNAL TABLE IF NOT EXISTS {database}.{table}(
      id                BIGINT,
      created_at        TIMESTAMP,
      updated_at        TIMESTAMP,
      data_source_id    VARCHAR(255),
      organization_id   BIGINT,
      name              VARCHAR(255),
      description       STRING,
      data_type         VARCHAR(255),
      attribute_type    VARCHAR(255)
    )
    PARTITIONED BY (partition_timestamp timestamp)
    STORED AS PARQUET
    LOCATION '{location}'
    TBLPROPERTIES("parquet.compress"="SNAPPY");
  database: "{{ var.value.get('server_env', 'prod') }}_segmentsvc"
  table: ls_data_source_attribute
  location: "s3://{{ var.value.get('server_env', 'prod') }}-buzzvil-data-lake/segmentsvc/landing_snapshot/data_source_attribute"
  partition:
    key: partition_timestamp
    value: "{{execution_date.strftime('%Y-%m-%d %H:00:00')}}"
    subdir: "year={{ execution_date.strftime('%Y') }}/month={{ execution_date.strftime('%m') }}/day={{ execution_date.strftime('%d') }}/hour={{ execution_date.strftime('%H') }}"