# CREATE TABLE `user_histories_inference` (
#   `viewer_id` varchar(255) NOT NULL,
#   `category_name` varchar(255) DEFAULT NULL,
#   `count` int(11) DEFAULT NULL,
#   `histories` text,
#   PRIMARY KEY (`viewer_id`)
# ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
---
pipeline_key: adrecommendersvc_ls_user_histories_inference
pipeline_type: mysql_unload_s3
pipeline_dag_configs:
  start_date: 2020-10-16 17:00:00
  schedule_interval: "0 17 * * *"
mysql:
  conn_id: adrecommendersvc_mysql
  table_name: user_histories_inference
  increment_key: name
  increment_key_type: dump
  fields:
  - viewer_id
  - category_name
  - count
  - histories
s3:
  bucket: "{{ var.value.get('server_env', 'prod') }}-buzzvil-data-lake"
  prefix: adrecommendersvc/landing_snapshot/user_histories_inference/year={year}/month={month}/day={day}/hour={hour}
  file_key: adrecommendersvc_ls_user_histories_inference
  data_format: parquet
athena:
  create_table_syntax: |
    CREATE EXTERNAL TABLE IF NOT EXISTS {database}.{table}(
      viewer_id       VARCHAR(1024),
      category_name   VARCHAR(1024),
      count           BIGINT,
      histories       VARCHAR(1024),
    )
    PARTITIONED BY (partition_timestamp timestamp)
    STORED AS PARQUET
    LOCATION '{location}'
    TBLPROPERTIES("parquet.compress"="SNAPPY");
  database: "{{ var.value.get('server_env', 'prod') }}_adrecommendersvc"
  table: ls_user_histories_inference
  location: "s3://{{ var.value.get('server_env', 'prod') }}-buzzvil-data-lake/adrecommendersvc/landing_snapshot/user_histories_inference"
  partition:
    key: partition_timestamp
    value: "{{execution_date.strftime('%Y-%m-%d %H:00:00')}}"
    subdir: "year={{ execution_date.strftime('%Y') }}/month={{ execution_date.strftime('%m') }}/day={{ execution_date.strftime('%d') }}/hour={{ execution_date.strftime('%H') }}"
