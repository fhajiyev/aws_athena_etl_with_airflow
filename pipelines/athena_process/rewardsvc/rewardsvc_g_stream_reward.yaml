# Schema mappings are from the following
# https://github.com/Buzzvil/rewardsvc/blob/master/internal/pkg/reward/rewardrepo/model.go
---
pipeline_key: rewardsvc_g_stream_reward
pipeline_type: athena_process
pipeline_dag_configs:
  start_date: 2020-04-29 00:00:00
  schedule_interval: "@hourly"

upstream_dependencies:
  - dag_id: athena_catalog_rewardsvc_l_reward
    timedelta_hours: 0

downstream_dependencies:
  - dag_id: athena_deduplicate_rewardsvc_g_reward
    task_id: generate_uuid

sensor_soft_fail: false

athena:
  workgroup: rewardsvc
  process_query: |
    CREATE TABLE IF NOT EXISTS {database}.{temp_table}
    WITH (
          format = 'PARQUET',
          parquet_compression = 'SNAPPY',
          external_location = 's3://{output_bucket}/{output_prefix}'
    ) AS (
        SELECT
          CAST(NewImage.aid.N AS BIGINT)                                                      AS account_id,
          CAST(NewImage.v.N AS BIGINT)                                                        AS version,
          CAST(NewImage.tid.S AS VARCHAR)                                                     AS transaction_id,
          CAST(NewImage.app.N AS BIGINT)                                                      AS app_id,
          CAST(NewImage.pid.S AS VARCHAR)                                                     AS publisher_user_id,
          CAST(NewImage.rid.N AS BIGINT)                                                      AS resource_id,
          CAST(NewImage.rt.S AS VARCHAR)                                                      AS resource_type,
          CAST(NewImage.et.S AS VARCHAR)                                                      AS event_type,
          CAST(NewImage.am.N AS BIGINT)                                                       AS amount,
          CAST(NewImage.rs.S AS VARCHAR)                                                      AS reward_status,
          FROM_UNIXTIME(CAST(NewImage.ca.N AS BIGINT))                                        AS created_at,
          FROM_UNIXTIME(CAST(NewImage.ua.N AS BIGINT))                                        AS updated_at,
          CAST(NewImage.sc.N AS BIGINT)                                                       AS scatter,
          CAST(JSON_EXTRACT_SCALAR(JSON_EXTRACT(NewImage.ext.S, '$.unit'), '$.id') AS BIGINT) AS unit_id,
          sequencenumber                                                                      AS dynamo_stream_seq_num,
          approximatecreationdatetime                                                         AS dynamo_stream_record_created_at,
          eventname                                                                           AS dynamo_stream_event_name
        from
          {{{{ var.value.get('server_env', 'prod') }}}}_rewardsvc.l_reward
        WHERE
          partition_timestamp >= TIMESTAMP'{start_time}' AND
          partition_timestamp < TIMESTAMP'{end_time}'
    );
  output_bucket: "{{ var.value.get('server_env', 'prod') }}-buzzvil-data-lake"
  output_prefix: rewardsvc/gold/stream_reward/year={year}/month={month}/day={day}/hour={hour}
  file_key: rewardsvc_g_stream_reward
  file_extension: parquet

  database: "{{ var.value.get('server_env', 'prod') }}_rewardsvc"
  table: g_stream_reward
  location: s3://{{ var.value.get('server_env', 'prod') }}-buzzvil-data-lake/rewardsvc/gold/stream_reward
  partition:
    name: partition_timestamp
    value: "{{ execution_date.strftime('%Y-%m-%d %H:00:00') }}"
    location: s3://{{{{ var.value.get('server_env', 'prod') }}}}-buzzvil-data-lake/rewardsvc/gold/stream_reward/year={year}/month={month}/day={day}/hour={hour}
  create_table_syntax: |
    CREATE EXTERNAL TABLE IF NOT EXISTS {database}.{table} (
      account_id          BIGINT,
      version             BIGINT,
      transaction_id      VARCHAR(72),
      app_id              BIGINT,
      publisher_user_id   VARCHAR(100),
      resource_id         BIGINT,
      resource_type       VARCHAR(16),
      event_type          VARCHAR(16),
      amount              BIGINT,
      reward_status       VARCHAR(16),
      created_at          TIMESTAMP,
      updated_at          TIMESTAMP,
      extra               VARCHAR(256),
      scatter             BIGINT,
      unit_id             BIGINT,
      dynamo_stream_seq_num             STRING,
      dynamo_stream_record_created_at   TIMESTAMP,
      dynamo_stream_event_name          VARCHAR(16)
    )
    PARTITIONED BY (partition_timestamp timestamp)
    STORED AS PARQUET
    LOCATION '{location}'
    tblproperties("parquet.compress"="SNAPPY");
