# Rather than updating DAU once per day, update DAU throughout the day by upserting adviewers hourly
---
pipeline_key: ba_imp_dau
pipeline_type: athena_redshift_sync
pipeline_dag_configs:
  start_date: 2019-01-01 16:00:00
  schedule_interval: "0 16 * * *"
athena:
  table_name: ba_impression
  create_table_syntax: |
    CREATE EXTERNAL TABLE spectrum.ba_impression (
      viewer_id          VARCHAR(64),
      unit_id            INT8,
      lineitem_id        INT8,
      time               TIMESTAMP,
      sales              FLOAT,
      year_of_birth      INT4,
      sex                VARCHAR(3),
      ip                 INT8,
      carrier            VARCHAR(128),
      region             VARCHAR(128),
      platform           VARCHAR(1),
      country            VARCHAR(2),
      device_name        VARCHAR(20),
      publisher_user_id  VARCHAR(256),
      relationship       VARCHAR(1),
      ifa                VARCHAR(64),
      udid               VARCHAR(64),
      adid               VARCHAR(64),
      creative_id        INT8,
      user_agent         VARCHAR(256),
      adnetwork_id       INT8,
      registered_days    INT4
    )
    PARTITIONED BY (
      partition_timestamp timestamp
    )
    ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
    WITH SERDEPROPERTIES (
      'serialization.format' = '1',
      'ignore.malformed.json' = 'true'
    )
    LOCATION 's3://prod-buzzvil-firehose/buzzad/impression/'
    ;
  partition:
    location: s3://prod-buzzvil-firehose/buzzad/impression
    name: partition_timestamp
    type: hourly
  process_query: |
    SELECT DISTINCT
      viewer_id                                                                           as viewer_id,
      unit_id                                                                             as unit_id,
      FIRST_VALUE(ifa)                           OVER ( PARTITION BY viewer_id, unit_id ) as ifa,
      FIRST_VALUE(COALESCE(registered_days,0))   OVER ( PARTITION BY viewer_id, unit_id ) as registered_days,
      DATE_TRUNC('day', partition_timestamp + interval '9' HOUR)                          as created_at
    FROM
      ba_impression
    WHERE
      partition_timestamp >= TIMESTAMP'{start_time}' - INTERVAL '1' HOUR AND
      partition_timestamp < TIMESTAMP'{end_time}' - INTERVAL '1' HOUR

  output_bucket: prod-buzzvil-data-lake
  output_prefix: buzzad/gold/imp_dau
  file_key: g_buzzad_imp_dau

redshift:
  table_name: g_buzzad_imp_dau
  fields:
  - viewer_id
  - unit_id
  - ifa
  - registered_days
  - created_at
  unique_key_list:
  - viewer_id
  - unit_id
  - created_at
  increment_key: created_at
  increment_key_type: timestamp
  copy_method: upsert
  create_table_syntax: |
    CREATE TABLE IF NOT EXISTS {table_name}
    (
        viewer_id               VARCHAR(64)     NOT NULL       ENCODE ZSTD,
        unit_id                 INT8            DEFAULT NULL   ENCODE ZSTD,
        ifa                     VARCHAR(64)     DEFAULT NULL   ENCODE ZSTD,
        registered_days         INT4            NOT NULL       ENCODE ZSTD,
        created_at              TIMESTAMP       NOT NULL       ENCODE ZSTD
    )
    DISTKEY(viewer_id)
    SORTKEY(created_at, unit_id)
